{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wR5bKeAqkhhy"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "X19E1QK6lJ0H",
    "outputId": "d7a01a73-4dfc-46c9-c99b-55126839317f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f3fa5481d68>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.linspace(0,10,1000)\n",
    "y = np.sin(x)\n",
    "ax.scatter(x,y, c = x, cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 911
    },
    "colab_type": "code",
    "id": "V1kU1hQW39JR",
    "outputId": "6ccbc821-0ce1-4500-a03c-58df57f5cc0f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')\n",
    "#%cd \"/content/drive/My Drive/NLP2/NLP2_Deep_Generative_Models_for_Text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jZeZcmqvkDWm"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class AFFRDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of items in the dataset\"\"\"\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the datapoint at index i as a tuple (sentence, label),\n",
    "        where the sentence is tokenized.\n",
    "        \"\"\"\n",
    "        encoded = self.tokenizer.encode(\n",
    "            self.sentences[idx], add_special_tokens=True)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "I4lIX2xH7zT2",
    "outputId": "a1796de5-adce-4ba0-e9b8-88cc8630d0e5"
   },
   "outputs": [],
   "source": [
    "from tokenizers import WordTokenizer\n",
    "\n",
    "# Create the datasets\n",
    "\n",
    "# Train your tokenizer.\n",
    "reader = nltk.corpus.BracketParseCorpusReader(\".\", \"02-21.10way.clean\")\n",
    "tree = reader.parsed_sents()[:]\n",
    "text = [\" \".join(line.leaves()).lower() for line in tree]\n",
    "tokenizer = WordTokenizer(text, max_vocab_size=10000)\n",
    "EOS = tokenizer.encode('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXt87J47l5ur"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: in an oct. 19 review of `` the misanthrope '' at chicago 's goodman theatre -lrb- `` revitalized classics take the stage in windy city , '' leisure & arts -rrb- , the role of celimene , played by kim cattrall , was mistakenly attributed to christina haag .\n",
      "tokenized: [4754, 926, 6325, 185, 7745, 6332, 584, 9060, 3, 10, 1161, 2002, 16, 4273, 9063, 22, 584, 3, 3, 8917, 9060, 8556, 4754, 3, 2067, 18, 10, 5363, 8, 1113, 24, 18, 9060, 7826, 6332, 3, 18, 6822, 1744, 5193, 3, 18, 9725, 5944, 1200, 9167, 3, 3, 25]\n",
      "decoded: in an oct. 19 review of `` the [UNK] '' at chicago 's goodman theatre -lrb- `` [UNK] [UNK] take the stage in [UNK] city , '' leisure & arts -rrb- , the role of [UNK] , played by kim [UNK] , was mistakenly attributed to [UNK] [UNK] .\n",
      "\n",
      "original: ms. haag plays elianti .\n",
      "tokenized: [6042, 3, 6826, 3, 25]\n",
      "decoded: ms. [UNK] plays [UNK] .\n",
      "\n",
      "original: rolls-royce motor cars inc. said it expects its u.s. sales to remain steady at about 1,200 cars in 1990 .\n",
      "tokenized: [3, 6021, 1860, 4760, 7923, 5028, 3647, 5034, 9388, 7929, 9167, 7554, 8603, 1161, 609, 41, 1860, 4754, 226, 25]\n",
      "decoded: [UNK] motor cars inc. said it expects its u.s. sales to remain steady at about 1,200 cars in 1990 .\n",
      "\n",
      "original: the luxury auto maker last year sold 1,214 cars in the u.s.\n",
      "tokenized: [9060, 5569, 1222, 5620, 5281, 9963, 8400, 3, 1860, 4754, 9060, 9388]\n",
      "decoded: the luxury auto maker last year sold [UNK] cars in the u.s.\n",
      "\n",
      "original: howard mosher , president and chief executive officer , said he anticipates growth for the luxury auto maker in britain and europe , and in far eastern markets .\n",
      "tokenized: [4638, 3, 18, 6996, 936, 2005, 3617, 6341, 18, 7923, 4466, 977, 4348, 3991, 9060, 5569, 1222, 5620, 4754, 1640, 936, 3551, 18, 936, 4754, 3760, 3297, 5687, 25]\n",
      "decoded: howard [UNK] , president and chief executive officer , said he anticipates growth for the luxury auto maker in britain and europe , and in far eastern markets .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if everything works.\n",
    "for sentence in text[:5]:\n",
    "    tokenized = tokenizer.encode(sentence, add_special_tokens=False)\n",
    "    sentence_decoded = tokenizer.decode(tokenized)\n",
    "    print('original:', sentence)\n",
    "    print('tokenized:', tokenized)\n",
    "    print('decoded:', sentence_decoded)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SQTuOkW4WTt"
   },
   "outputs": [],
   "source": [
    "files = [\"02-21.10way.clean\", \"22.auto.clean\", \"23.auto.clean\"]\n",
    "\n",
    "# Get output dict and remapping of file names to dataset names\n",
    "data_dict = {}\n",
    "remap_dict = {\"02-21.10way.clean\":\"train\", \n",
    "              \"22.auto.clean\":\"validation\",\n",
    "              \"23.auto.clean\":\"test\"}\n",
    "\n",
    "# Parse the data with nltk bracket parser\n",
    "for file in files:\n",
    "    reader = nltk.corpus.BracketParseCorpusReader(\".\", file)\n",
    "    tree = reader.parsed_sents()[:]\n",
    "    \n",
    "    # Assign a dataset dict to train, validation or test\n",
    "    data_dict[remap_dict[file]] = [\" \".join(line.leaves()).lower() for line in tree]\n",
    "\n",
    "train_data = AFFRDataset(data_dict['train'], tokenizer)\n",
    "validation_data = AFFRDataset(data_dict['validation'], tokenizer)\n",
    "test_data = AFFRDataset(data_dict['test'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ORk2CU_8qYfA"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TextGenerationModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, gru_num_hidden=256, gru_num_layers=2, device='cuda:0',dropout=0):\n",
    "        super(TextGenerationModel, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size,256)\n",
    "        self.gru = nn.GRU(256,gru_num_hidden,gru_num_layers,dropout=dropout,batch_first=True)\n",
    "        self.output = nn.Linear(gru_num_hidden,vocab_size)\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        input = x.to(self.device)\n",
    "        embed = self.embed(input)\n",
    "        if(hidden == None):\n",
    "            out,hidden = self.gru.forward(embed)\n",
    "        else:\n",
    "            out,hidden = self.gru.forward(embed,hidden)\n",
    "        out = self.output(out)\n",
    "\n",
    "        return out, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hC-pZ4WCnXPB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def padded_collate(batch):\n",
    "    \"\"\"Pad sentences, return sentences and labels as LongTensors.\"\"\"\n",
    "    sentences = [sentence[:-1] for sentence in batch]\n",
    "    labels = [sentence[1:] for sentence in batch]\n",
    "\n",
    "    lengths = [len(s) for s in sentences]\n",
    "    max_length = max(lengths)\n",
    "    # Pad each sentence with zeros to max_length\n",
    "    padded_sents = [s + [0] * (max_length - len(s)) for s in sentences]\n",
    "    padded_labels = [s + [0] * (max_length - len(s)) for s in labels]\n",
    "    return torch.LongTensor(padded_sents), torch.LongTensor(padded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RWgqPpkpo7jL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def train(config, train_data, valid_data):\n",
    "\n",
    "    # Initialize the device which to run the model on\n",
    "    if(torch.cuda.is_available()):\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('Device = CUDA')\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print('Device = CPU')\n",
    "        \n",
    "    #Paths to save the model and optimizer to\n",
    "    modelpath = config['model_path']\n",
    "    optimpath = config['optim_path']\n",
    "\n",
    "    # Initialize the model that we are going to use\n",
    "    makeNew = config['new_model']\n",
    "\n",
    "    #Load in model if necessary\n",
    "    if(not makeNew and modelpath != \"\"):\n",
    "        model = (torch.load(modelpath))\n",
    "    else:\n",
    "        model = TextGenerationModel(config['vocab_size'],config['num_hidden'],config['num_layers'],device)\n",
    "\n",
    "    # Setup the loss and optimizer\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(model.parameters(),config['learning_rate'])\n",
    "\n",
    "    #Load in the optimizer if necessary\n",
    "    if(not makeNew and optimpath != \"\"):\n",
    "        optimizer.load_state_dict(torch.load(optimpath))\n",
    "\n",
    "    accs = []\n",
    "    losses = []\n",
    "    curr_accs = []\n",
    "    curr_losses = []\n",
    "    print_steps = []\n",
    "    convergence = False\n",
    "    conv_count = 0\n",
    "    prev_loss = np.inf\n",
    "\n",
    "    iteration = 0\n",
    "    epoch = 0\n",
    "    while(not convergence):\n",
    "        print(\"Epoch: \" + str(epoch))\n",
    "        loss = 0\n",
    "        accuracy = 0\n",
    "        for step, (batch_inputs, batch_targets) in enumerate(train_data):\n",
    "            # Only for time measurement of step through network\n",
    "            t1 = time.time()\n",
    "            optimizer.zero_grad()\n",
    "            targets = batch_targets.to(device)\n",
    "            out,_ = model.forward(batch_inputs)\n",
    "\n",
    "            #Calculate loss and accuracy\n",
    "            curr_loss = 0\n",
    "            curr_acc = 0\n",
    "            cor = 0\n",
    "\n",
    "            seq_length = batch_inputs.shape[1]\n",
    "\n",
    "            # Get average original lenghts of sentences to divide total loss by\n",
    "            orig_lengths = torch.mean(torch.argmin(batch_inputs,dim=1).float())\n",
    "\n",
    "            for i in range(seq_length):\n",
    "                out_t = out[:,i,:]\n",
    "                targets_t = targets[:,i]\n",
    "                curr_loss += criterion.forward(out_t, targets_t)\n",
    "                preds = (torch.argmax(out_t,dim=1)).long()\n",
    "                cor += targets_t.eq(preds).sum().item()\n",
    "            curr_acc = cor/(seq_length * targets.size()[0])\n",
    "            loss += curr_loss.item()\n",
    "            accuracy += curr_acc\n",
    "\n",
    "            curr_loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config['max_norm'])\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            curr_accs.append(curr_acc)\n",
    "            curr_losses.append(curr_loss.item())\n",
    "\n",
    "            # Just for time measurement\n",
    "            t2 = time.time()\n",
    "            examples_per_second = config['batch_size']/float(t2-t1)\n",
    "            if(iteration % config['print_every'] == 0):\n",
    "                loss_std = np.std(curr_losses)\n",
    "                print(\"[{}] Epoch {:04d}, Train Step {:04d}, Batch Size = {}, Examples/Sec = {:.2f}, \"\n",
    "                    \"Avg. Accuracy = {:.2f}, Avg. Loss = {:.3f}, Loss STD = {:.3f}\".format(\n",
    "                        datetime.now().strftime(\"%Y-%m-%d %H:%M\"), epoch, iteration,\n",
    "                        config['batch_size'], examples_per_second,\n",
    "                        accuracy/config['print_every'], loss/config['print_every'], loss_std\n",
    "                ))\n",
    "                accs.append(accuracy/config['print_every'])\n",
    "                losses.append(loss/config['print_every'])\n",
    "                print_steps.append(iteration)\n",
    "                if(np.abs(prev_loss/config['print_every'] - loss/config['print_every']) < 0.001):\n",
    "                    conv_count += 1\n",
    "                else:\n",
    "                    conv_count = 0\n",
    "                convergence = conv_count == 5\n",
    "                prev_loss = loss\n",
    "                accuracy = 0\n",
    "                loss = 0\n",
    "            #Generate text\n",
    "            if iteration % config['sample_every'] == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    text = generate_text(model,device,config['sample_strat'],config['sample_temp'])\n",
    "                    print(str(iteration), \": \", text)\n",
    "                model.train()\n",
    "                '''                if(modelpath != \"\"):\n",
    "                    torch.save(model,modelpath)\n",
    "                if(optimpath != \"\"):\n",
    "                    torch.save(optimizer.state_dict(),optimpath)'''\n",
    "            iteration += 1\n",
    "\n",
    "        #TODO: Validate\n",
    "        model.eval()\n",
    "        iter = 0\n",
    "        for step, (batch_inputs, batch_targets) in enumerate(valid_data):\n",
    "            targets = batch_targets.to(device)\n",
    "            out,_ = model.forward(batch_inputs)\n",
    "            #Calculate loss and accuracy\n",
    "            curr_loss = 0\n",
    "            curr_acc = 0\n",
    "            cor = 0\n",
    "\n",
    "            seq_length = batch_inputs.shape[1]\n",
    "\n",
    "            # Get average original lenghts of sentences to divide total loss by\n",
    "            orig_lengths = torch.mean(torch.argmin(batch_inputs,dim=1).float())\n",
    "\n",
    "            for i in range(seq_length):\n",
    "                out_t = out[:,i,:]\n",
    "                targets_t = targets[:,i]\n",
    "                curr_loss += criterion.forward(out_t, targets_t)\n",
    "                preds = (torch.argmax(out_t,dim=1)).long()\n",
    "                cor += targets_t.eq(preds).sum().item()\n",
    "            curr_acc = cor/(seq_length * targets.size()[0])\n",
    "            loss += curr_loss.item()\n",
    "            accuracy += curr_acc\n",
    "            curr_accs.append(curr_acc)\n",
    "            curr_losses.append(curr_loss.item())\n",
    "            iter += 1\n",
    "        loss_std = np.std(curr_losses)\n",
    "        print(\"Epoch {:04d}, Validation, Avg. Accuracy = {:.2f}, Avg. Loss = {:.3f}, Loss STD = {:.3f}\".format(\n",
    "                epoch, accuracy/iter, loss/iter, loss_std))\n",
    "        model.train()\n",
    "        epoch += 1\n",
    "        if(epoch == config['epochs'] or convergence):\n",
    "            break\n",
    "\n",
    "    print('Done training.')\n",
    "    print(accs)\n",
    "    print(losses)\n",
    "    print(print_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzJ0VAMeYHSb"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def generate_text(model,device,sampling_strat='max',temperature=1, starting_text=[1],ksize=1):\n",
    "    assert sampling_strat in ('max', 'rand')\n",
    "    \n",
    "    # Start with encoded text\n",
    "    start = np.array(starting_text)\n",
    "    text = list(start) #This stores the eventual output\n",
    "    current = torch.from_numpy(start).long().unsqueeze(dim=0) \n",
    "\n",
    "    #The initial step\n",
    "    input = current.to(device)\n",
    "    output,hidden = model.forward(input)\n",
    "    current = output[0,-1,:].squeeze()\n",
    "    if(sampling_strat == 'max'):\n",
    "        guess = torch.argmax(current).unsqueeze(0)\n",
    "    elif(sampling_strat == 'rand'):\n",
    "        guess = torch.multinomial(F.softmax(temperature*current,dim=0),1)\n",
    "    text.append(guess.item())\n",
    "    input = guess.unsqueeze(0)\n",
    "\n",
    "    #Now that we have an h and c, we can start the loop\n",
    "    i = 0\n",
    "    while(i < 100):\n",
    "        output,hidden = model.forward(input,hidden)\n",
    "        current = output.squeeze()\n",
    "        if(sampling_strat == 'max'):\n",
    "            guess = torch.argmax(current).unsqueeze(0)\n",
    "        elif(sampling_strat == 'rand'):\n",
    "            guess = torch.multinomial(F.softmax(temperature*current,dim=0),1)\n",
    "        text.append(guess.item())\n",
    "        input = guess.unsqueeze(0)\n",
    "        i += 1\n",
    "        if(guess.item() == 2):\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-B1V5dagp3z9",
    "outputId": "0089d545-cebb-4438-fc3b-0fcf9345f5aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config = {}\\n\\n# Model params\\nconfig[\\'model_path\\'] = \"models\\\\trump_model.txt\"\\nconfig[\\'optim_path\\']=\"models\\\\trump_optim.txt\"\\nconfig[\\'new_model\\']=True\\nconfig[\\'num_hidden\\']=128\\nconfig[\\'num_layers\\']=2\\nconfig[\\'vocab_size\\']=tokenizer.vocab_size\\n\\n# Training params\\nconfig[\\'batch_size\\']=64\\nconfig[\\'learning_rate\\']=2e-3\\n\\n# It is not necessary to implement the following three params, but it may help training.\\nconfig[\\'learning_rate_decay\\']=0.96\\nconfig[\\'learning_rate_step\\']=5000\\nconfig[\\'dropout_keep_prob\\']=1\\nconfig[\\'epochs\\']=10\\nconfig[\\'max_norm\\']=5.0\\n\\n# Misc params\\nconfig[\\'print_every\\']=100\\nconfig[\\'sample_every\\']=100\\nconfig[\\'sample_strat\\']=\\'rand\\'\\nconfig[\\'sample_temp\\']=1.5\\n\\n# Create dataloaders\\ntrain_loader = DataLoader(train_data, batch_size=config[\\'batch_size\\'], shuffle=True, collate_fn=padded_collate)\\nvalid_loader = DataLoader(validation_data, batch_size=256, shuffle=False, collate_fn=padded_collate)\\ntest_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=padded_collate)\\n\\n# Train the model\\ntrain(config, train_loader, valid_loader)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''config = {}\n",
    "\n",
    "# Model params\n",
    "config['model_path'] = \"models\\\\trump_model.txt\"\n",
    "config['optim_path']=\"models\\\\trump_optim.txt\"\n",
    "config['new_model']=True\n",
    "config['num_hidden']=128\n",
    "config['num_layers']=2\n",
    "config['vocab_size']=tokenizer.vocab_size\n",
    "\n",
    "# Training params\n",
    "config['batch_size']=64\n",
    "config['learning_rate']=2e-3\n",
    "\n",
    "# It is not necessary to implement the following three params, but it may help training.\n",
    "config['learning_rate_decay']=0.96\n",
    "config['learning_rate_step']=5000\n",
    "config['dropout_keep_prob']=1\n",
    "config['epochs']=10\n",
    "config['max_norm']=5.0\n",
    "\n",
    "# Misc params\n",
    "config['print_every']=100\n",
    "config['sample_every']=100\n",
    "config['sample_strat']='rand'\n",
    "config['sample_temp']=1.5\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=config['batch_size'], shuffle=True, collate_fn=padded_collate)\n",
    "valid_loader = DataLoader(validation_data, batch_size=256, shuffle=False, collate_fn=padded_collate)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=padded_collate)\n",
    "\n",
    "# Train the model\n",
    "train(config, train_loader, valid_loader)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSoMf9mCcWsN"
   },
   "source": [
    "# Sentence VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "AN4v_77RcChw",
    "outputId": "a6614ea6-7f54-41f6-8409-2e5ec9e0c7f3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from SentenceVAE import run_epoch\n",
    "from SentenceVAE import SentenceVAE\n",
    "from torch.optim import Adam\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "epochs = 10\n",
    "zdim = 13\n",
    "batch_size = 64\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=padded_collate)\n",
    "valid_loader = DataLoader(validation_data, batch_size=256, shuffle=False, collate_fn=padded_collate)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False, collate_fn=padded_collate)\n",
    "\n",
    "model = SentenceVAE(vocab_size, z_dim=zdim) \n",
    "model.to(device)\n",
    "#sampled = model.sample(9,device)[0]\n",
    "\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "train_curve, val_curve = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    elbos = run_epoch(model, (train_loader, valid_loader), optimizer, device)\n",
    "    train_elbo, val_elbo = elbos\n",
    "    train_curve.append(train_elbo)\n",
    "    val_curve.append(val_elbo)\n",
    "    print(f\"[Epoch {epoch}] train elbo: {train_elbo} val_elbo: {val_elbo}\")\n",
    "    \n",
    "    #sampled = model.sample(9, device)[0]\n",
    "\n",
    "save_elbo_plot(train_curve, val_curve, 'elbo.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP2_Deep_Generative_Models_for_Text.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
